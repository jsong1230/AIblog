#!/usr/bin/env python3
"""
í‚¤ì›Œë“œ ì„±ê³¼ ì¶”ì  ì‹œìŠ¤í…œ
ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ ì„±ê³¼ë¥¼ ì¶”ì í•˜ê³  í‚¤ì›Œë“œë³„ í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import csv
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from collections import defaultdict
import re

PERFORMANCE_DB = Path("data/keyword_performance.json")
CONTENT_DIR = Path("content/post")

class KeywordPerformanceTracker:
    def __init__(self):
        self.performance_db = self.load_performance_db()
        self.content_dir = CONTENT_DIR
        self.content_dir.mkdir(parents=True, exist_ok=True)
        PERFORMANCE_DB.parent.mkdir(parents=True, exist_ok=True)
    
    def load_performance_db(self) -> Dict:
        """ì„±ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        if PERFORMANCE_DB.exists():
            with open(PERFORMANCE_DB, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def save_performance_db(self):
        """ì„±ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        with open(PERFORMANCE_DB, 'w', encoding='utf-8') as f:
            json.dump(self.performance_db, f, ensure_ascii=False, indent=2)
    
    def extract_keyword_from_filename(self, filename: str) -> Optional[str]:
        """íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # íŒŒì¼ëª… í˜•ì‹: YYYY-MM-DD-keyword-slug-timestamp.md
        # ë˜ëŠ”: YYYY-MM-DD-keyword-slug-timestamp.en.md
        match = re.match(r'\d{4}-\d{2}-\d{2}-(.+?)-(\d+|timestamp)', filename)
        if match:
            keyword_slug = match.group(1)
            # slugë¥¼ í‚¤ì›Œë“œë¡œ ë³€í™˜ (í•˜ì´í”ˆì„ ê³µë°±ìœ¼ë¡œ)
            keyword = keyword_slug.replace('-', ' ')
            return keyword
        return None
    
    def get_post_files(self) -> List[Path]:
        """ëª¨ë“  í¬ìŠ¤íŠ¸ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        if not self.content_dir.exists():
            return []
        
        return list(self.content_dir.glob("*.md"))
    
    def analyze_post(self, post_file: Path) -> Dict:
        """í¬ìŠ¤íŠ¸ íŒŒì¼ ë¶„ì„"""
        try:
            import frontmatter
            
            with open(post_file, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keyword = post.metadata.get('title', '')
            if not keyword:
                keyword = self.extract_keyword_from_filename(post_file.name)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            return {
                'keyword': keyword,
                'title': post.metadata.get('title', ''),
                'date': post.metadata.get('date', ''),
                'categories': post.metadata.get('categories', []),
                'tags': post.metadata.get('tags', []),
                'description': post.metadata.get('description', ''),
                'content_length': len(post.content),
                'filename': post_file.name,
            }
        except Exception as e:
            print(f"âš ï¸  í¬ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨ ({post_file.name}): {e}")
            return None
    
    def update_keyword_performance(self, keyword: str, metrics: Dict):
        """í‚¤ì›Œë“œ ì„±ê³¼ ì—…ë°ì´íŠ¸"""
        if keyword not in self.performance_db:
            self.performance_db[keyword] = {
                'keyword': keyword,
                'post_count': 0,
                'total_views': 0,
                'total_shares': 0,
                'avg_content_length': 0,
                'first_post_date': None,
                'last_post_date': None,
                'categories': set(),
                'tags': set(),
            }
        
        kw_data = self.performance_db[keyword]
        kw_data['post_count'] += 1
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        if 'views' in metrics:
            kw_data['total_views'] += metrics['views']
        if 'shares' in metrics:
            kw_data['total_shares'] += metrics['shares']
        if 'content_length' in metrics:
            current_avg = kw_data['avg_content_length']
            post_count = kw_data['post_count']
            kw_data['avg_content_length'] = (
                (current_avg * (post_count - 1) + metrics['content_length']) / post_count
            )
        
        # ë‚ ì§œ ì—…ë°ì´íŠ¸
        if 'date' in metrics:
            date_str = metrics['date']
            if not kw_data['first_post_date'] or date_str < kw_data['first_post_date']:
                kw_data['first_post_date'] = date_str
            if not kw_data['last_post_date'] or date_str > kw_data['last_post_date']:
                kw_data['last_post_date'] = date_str
        
        # ì¹´í…Œê³ ë¦¬/íƒœê·¸ ì—…ë°ì´íŠ¸
        if 'categories' in metrics:
            if isinstance(kw_data['categories'], set):
                kw_data['categories'].update(metrics['categories'])
            else:
                kw_data['categories'] = set(metrics['categories'])
        
        if 'tags' in metrics:
            if isinstance(kw_data['tags'], set):
                kw_data['tags'].update(metrics['tags'])
            else:
                kw_data['tags'] = set(metrics['tags'])
        
        # setì„ listë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
        kw_data['categories'] = list(kw_data.get('categories', set()))
        kw_data['tags'] = list(kw_data.get('tags', set()))
    
    def scan_all_posts(self):
        """ëª¨ë“  í¬ìŠ¤íŠ¸ ìŠ¤ìº” ë° ì„±ê³¼ ì—…ë°ì´íŠ¸"""
        print("ğŸ” í¬ìŠ¤íŠ¸ ìŠ¤ìº” ì‹œì‘...")
        
        post_files = self.get_post_files()
        print(f"ğŸ“Š ë°œê²¬ëœ í¬ìŠ¤íŠ¸: {len(post_files)}ê°œ")
        
        for post_file in post_files:
            analysis = self.analyze_post(post_file)
            if analysis:
                metrics = {
                    'content_length': analysis['content_length'],
                    'date': analysis['date'],
                    'categories': analysis['categories'],
                    'tags': analysis['tags'],
                }
                self.update_keyword_performance(analysis['keyword'], metrics)
        
        self.save_performance_db()
        print(f"âœ… ìŠ¤ìº” ì™„ë£Œ: {len(self.performance_db)}ê°œ í‚¤ì›Œë“œ ì¶”ì  ì¤‘")
    
    def get_top_keywords(self, metric: str = 'post_count', limit: int = 10) -> List[Dict]:
        """ìƒìœ„ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°"""
        if not self.performance_db:
            return []
        
        sorted_keywords = sorted(
            self.performance_db.items(),
            key=lambda x: x[1].get(metric, 0),
            reverse=True
        )
        
        return [
            {'keyword': kw, **data}
            for kw, data in sorted_keywords[:limit]
        ]
    
    def print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        if not self.performance_db:
            print("ğŸ“Š ì¶”ì  ì¤‘ì¸ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        total_keywords = len(self.performance_db)
        total_posts = sum(kw['post_count'] for kw in self.performance_db.values())
        
        print(f"\nğŸ“Š í‚¤ì›Œë“œ ì„±ê³¼ í†µê³„:")
        print(f"   ì¶”ì  ì¤‘ì¸ í‚¤ì›Œë“œ: {total_keywords}ê°œ")
        print(f"   ì´ í¬ìŠ¤íŠ¸ ìˆ˜: {total_posts}ê°œ")
        print(f"   í‰ê·  í¬ìŠ¤íŠ¸/í‚¤ì›Œë“œ: {total_posts/total_keywords:.1f}ê°œ")
        
        # ìƒìœ„ í‚¤ì›Œë“œ ì¶œë ¥
        print(f"\nğŸ† í¬ìŠ¤íŠ¸ ìˆ˜ ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ:")
        top_keywords = self.get_top_keywords('post_count', 10)
        for i, kw_data in enumerate(top_keywords, 1):
            print(f"   {i}. {kw_data['keyword']}: {kw_data['post_count']}ê°œ í¬ìŠ¤íŠ¸")
    
    def export_to_csv(self, output_file: Path = Path("data/keyword_performance.csv")):
        """ì„±ê³¼ ë°ì´í„°ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°"""
        if not self.performance_db:
            print("âš ï¸  ë‚´ë³´ë‚¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            fieldnames = ['í‚¤ì›Œë“œ', 'í¬ìŠ¤íŠ¸ìˆ˜', 'ì´ì¡°íšŒìˆ˜', 'ì´ê³µìœ ìˆ˜', 'í‰ê· ë‚´ìš©ê¸¸ì´', 
                         'ì²«í¬ìŠ¤íŠ¸ì¼ì', 'ë§ˆì§€ë§‰í¬ìŠ¤íŠ¸ì¼ì', 'ì¹´í…Œê³ ë¦¬', 'íƒœê·¸']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for keyword, data in self.performance_db.items():
                writer.writerow({
                    'í‚¤ì›Œë“œ': keyword,
                    'í¬ìŠ¤íŠ¸ìˆ˜': data.get('post_count', 0),
                    'ì´ì¡°íšŒìˆ˜': data.get('total_views', 0),
                    'ì´ê³µìœ ìˆ˜': data.get('total_shares', 0),
                    'í‰ê· ë‚´ìš©ê¸¸ì´': int(data.get('avg_content_length', 0)),
                    'ì²«í¬ìŠ¤íŠ¸ì¼ì': data.get('first_post_date', ''),
                    'ë§ˆì§€ë§‰í¬ìŠ¤íŠ¸ì¼ì': data.get('last_post_date', ''),
                    'ì¹´í…Œê³ ë¦¬': ', '.join(data.get('categories', [])),
                    'íƒœê·¸': ', '.join(data.get('tags', [])),
                })
        
        print(f"âœ… CSV ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_file}")

if __name__ == "__main__":
    tracker = KeywordPerformanceTracker()
    
    # ëª¨ë“  í¬ìŠ¤íŠ¸ ìŠ¤ìº”
    tracker.scan_all_posts()
    
    # í†µê³„ ì¶œë ¥
    tracker.print_statistics()
    
    # CSV ë‚´ë³´ë‚´ê¸°
    tracker.export_to_csv()
